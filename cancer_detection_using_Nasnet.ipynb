{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cancer_detection_using_Nasnet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasohasakii/kaggle_histopathologic_cancer_detection/blob/master/cancer_detection_using_Nasnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pVXTox4FiWG",
        "colab_type": "text"
      },
      "source": [
        "## Loading Kaggle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2L3NJtuMkOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/yasohasakii/kaggle_histopathologic_cancer_detection.git\n",
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle_histopathologic_cancer_detection/kaggle.json ~/.kaggle/kaggle.json\n",
        "!rm -rf kaggle_histopathologic_cancer_detection sample_data\n",
        "!kaggle competitions download -c histopathologic-cancer-detection\n",
        "!mkdir test\n",
        "!mkdir train\n",
        "!unzip test.zip -d test\n",
        "!unzip train.zip -d train\n",
        "!unzip sample_submission.csv.zip\n",
        "!unzip train_labels.csv.zip\n",
        "!rm *.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDgHIiNBOIpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "from random import shuffle\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Convolution1D, concatenate, SpatialDropout1D, GlobalMaxPool1D, GlobalAvgPool1D, Embedding, \\\n",
        "    Conv2D, SeparableConv1D, Add, BatchNormalization, Activation, GlobalAveragePooling2D, LeakyReLU, Flatten\n",
        "from keras.layers import Dense, Input, Dropout, MaxPooling2D, Concatenate, GlobalMaxPooling2D, GlobalAveragePooling2D, \\\n",
        "    Lambda, Multiply, LSTM, Bidirectional, PReLU, MaxPooling1D\n",
        "from keras.layers.pooling import _GlobalPooling1D\n",
        "from keras.losses import mae, sparse_categorical_crossentropy, binary_crossentropy\n",
        "from keras.models import Model\n",
        "from keras.applications.nasnet import NASNetMobile, NASNetLarge, preprocess_input\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from imgaug import augmenters as iaa\n",
        "import imgaug as ia"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbH8fU7sFtzH",
        "colab_type": "text"
      },
      "source": [
        "## Split Train dataset and Validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6QioBiuattb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_id_from_file_path(file_path):\n",
        "    return file_path.split(os.path.sep)[-1].replace('.tif', '')\n",
        "df_train = pd.read_csv(\"./train_labels.csv\")\n",
        "id_label_map = {k:v for k,v in zip(df_train.id.values, df_train.label.values)}\n",
        "df_train.head()\n",
        "labeled_files = glob('./train/*.tif')\n",
        "test_files = glob('./test/*.tif')\n",
        "print(\"labeled_files size :\", len(labeled_files))\n",
        "print(\"test_files size :\", len(test_files))\n",
        "train, val = train_test_split(labeled_files, test_size=0.1, random_state=101010)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcT3DbmfF4re",
        "colab_type": "text"
      },
      "source": [
        "## Define image generator\n",
        "using imgaug module as an image generator, when it's processing train dataset, image would be agumented by random paraments, while validation dataset wouldn't. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYSCcKaza3I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chunker(seq, size):\n",
        "    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n",
        "def get_seq():\n",
        "    sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
        "    seq = iaa.Sequential(\n",
        "        [\n",
        "            # apply the following augmenters to most images\n",
        "            iaa.Fliplr(0.5), # horizontally flip 50% of all images\n",
        "            iaa.Flipud(0.2), # vertically flip 20% of all images\n",
        "            sometimes(iaa.Affine(\n",
        "                scale={\"x\": (0.9, 1.1), \"y\": (0.9, 1.1)}, # scale images to 80-120% of their size, individually per axis\n",
        "                translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, # translate by -20 to +20 percent (per axis)\n",
        "                rotate=(-10, 10), # rotate by -45 to +45 degrees\n",
        "                shear=(-5, 5), # shear by -16 to +16 degrees\n",
        "                order=[0, 1], # use nearest neighbour or bilinear interpolation (fast)\n",
        "                cval=(0, 255), # if mode is constant, use a cval between 0 and 255\n",
        "                mode=ia.ALL # use any of scikit-image's warping modes (see 2nd image from the top for examples)\n",
        "            )),\n",
        "            # execute 0 to 5 of the following (less important) augmenters per image\n",
        "            # don't execute all of them, as that would often be way too strong\n",
        "            iaa.SomeOf((0, 5),\n",
        "                [\n",
        "                    sometimes(iaa.Superpixels(p_replace=(0, 1.0), n_segments=(20, 200))), # convert images into their superpixel representation\n",
        "                    iaa.OneOf([\n",
        "                        iaa.GaussianBlur((0, 1.0)), # blur images with a sigma between 0 and 3.0\n",
        "                        iaa.AverageBlur(k=(3, 5)), # blur image using local means with kernel sizes between 2 and 7\n",
        "                        iaa.MedianBlur(k=(3, 5)), # blur image using local medians with kernel sizes between 2 and 7\n",
        "                    ]),\n",
        "                    iaa.Sharpen(alpha=(0, 1.0), lightness=(0.9, 1.1)), # sharpen images\n",
        "                    iaa.Emboss(alpha=(0, 1.0), strength=(0, 2.0)), # emboss images\n",
        "                    # search either for all edges or for directed edges,\n",
        "                    # blend the result with the original image using a blobby mask\n",
        "                    iaa.SimplexNoiseAlpha(iaa.OneOf([\n",
        "                        iaa.EdgeDetect(alpha=(0.5, 1.0)),\n",
        "                        iaa.DirectedEdgeDetect(alpha=(0.5, 1.0), direction=(0.0, 1.0)),\n",
        "                    ])),\n",
        "                    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.01*255), per_channel=0.5), # add gaussian noise to images\n",
        "                    iaa.OneOf([\n",
        "                        iaa.Dropout((0.01, 0.05), per_channel=0.5), # randomly remove up to 10% of the pixels\n",
        "                        iaa.CoarseDropout((0.01, 0.03), size_percent=(0.01, 0.02), per_channel=0.2),\n",
        "                    ]),\n",
        "                    iaa.Invert(0.01, per_channel=True), # invert color channels\n",
        "                    iaa.Add((-2, 2), per_channel=0.5), # change brightness of images (by -10 to 10 of original value)\n",
        "                    iaa.AddToHueAndSaturation((-1, 1)), # change hue and saturation\n",
        "                    # either change the brightness of the whole image (sometimes\n",
        "                    # per channel) or change the brightness of subareas\n",
        "                    iaa.OneOf([\n",
        "                        iaa.Multiply((0.9, 1.1), per_channel=0.5),\n",
        "                        iaa.FrequencyNoiseAlpha(\n",
        "                            exponent=(-1, 0),\n",
        "                            first=iaa.Multiply((0.9, 1.1), per_channel=True),\n",
        "                            second=iaa.ContrastNormalization((0.9, 1.1))\n",
        "                        )\n",
        "                    ]),\n",
        "                    sometimes(iaa.ElasticTransformation(alpha=(0.5, 3.5), sigma=0.25)), # move pixels locally around (with random strengths)\n",
        "                    sometimes(iaa.PiecewiseAffine(scale=(0.01, 0.05))), # sometimes move parts of the image around\n",
        "                    sometimes(iaa.PerspectiveTransform(scale=(0.01, 0.1)))\n",
        "                ],\n",
        "                random_order=True\n",
        "            )\n",
        "        ],\n",
        "        random_order=True\n",
        "    )\n",
        "    return seq\n",
        "\n",
        "def data_gen(list_files, id_label_map, batch_size, augment=False):\n",
        "    seq = get_seq()\n",
        "    while True:\n",
        "        shuffle(list_files)\n",
        "        for batch in chunker(list_files, batch_size):\n",
        "            X = [cv2.imread(x) for x in batch]\n",
        "            Y = [id_label_map[get_id_from_file_path(x)] for x in batch]\n",
        "            if augment:\n",
        "                X = seq.augment_images(X)\n",
        "            X = [preprocess_input(x) for x in X]\n",
        "                \n",
        "            yield np.array(X), np.array(Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brULFFvNGqKF",
        "colab_type": "text"
      },
      "source": [
        "## Define model structure\n",
        "using NasNet mobile version without pretrained paraments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NleUJQembVna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_classif_nasnet():\n",
        "    inputs = Input((96, 96, 3))\n",
        "    base_model = NASNetMobile(include_top=False, input_tensor=inputs, weights=None)\n",
        "    x = base_model(inputs)\n",
        "    out1 = GlobalMaxPooling2D()(x)\n",
        "    out2 = GlobalAveragePooling2D()(x)\n",
        "    out3 = Flatten()(x)\n",
        "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
        "    out = Dropout(0.5)(out)\n",
        "    out = Dense(1, activation=\"sigmoid\", name=\"3_\")(out)\n",
        "    model = Model(inputs, out)\n",
        "    model.compile(optimizer=Adam(0.0001), loss=binary_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "\n",
        "    return model\n",
        "model = get_model_classif_nasnet()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkDUyAaoE03f",
        "colab_type": "text"
      },
      "source": [
        "## Model Training\n",
        "It'd auto-save model paraments once better validation dataset accuracy model comes out, the path is './model.h5'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGZ88X6cbhWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size=32\n",
        "h5_path = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(h5_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "history = model.fit_generator(\n",
        "    data_gen(train, id_label_map, batch_size, augment=True),\n",
        "    validation_data=data_gen(val, id_label_map, batch_size),\n",
        "    epochs=10, verbose=1,\n",
        "    callbacks=[checkpoint],\n",
        "    steps_per_epoch=len(train) // batch_size,\n",
        "    validation_steps=len(val) // batch_size)\n",
        "batch_size=64\n",
        "history = model.fit_generator(\n",
        "    data_gen(train, id_label_map, batch_size, augment=True),\n",
        "    validation_data=data_gen(val, id_label_map, batch_size),\n",
        "    epochs=6, verbose=1,\n",
        "    callbacks=[checkpoint],\n",
        "    steps_per_epoch=len(train) // batch_size,\n",
        "    validation_steps=len(val) // batch_size)\n",
        "\n",
        "model.load_weights(h5_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgOtULJBdjYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}